{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db37d826",
   "metadata": {},
   "source": [
    "## This notebook shows how PCA helps accelerate data market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26559a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamarket import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0d2de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all seller datasets\n",
    "# read buyer dataste\n",
    "# clean_covariance() is not necessary. Originally to make covariance sparse. Doesn't matter...\n",
    "crime = pd.read_csv(\"crime.csv\")\n",
    "crimedata = agg_dataset()\n",
    "crimedata.load(crime, [], [\"DBN\"], \"crime\")\n",
    "crimedata.find_features()\n",
    "crimedata.remove_redundant_columns()\n",
    "crimedata.standardize_all()\n",
    "crimedata.compute_agg(True)\n",
    "crimedata.clean_covariance()\n",
    "\n",
    "esl = pd.read_csv(\"esl.csv\")\n",
    "esldata = agg_dataset()\n",
    "esldata.load(esl, [], [[\"DBN\",\"Grade\"]], \"esl\")\n",
    "esldata.find_features()\n",
    "esldata.remove_redundant_columns()\n",
    "esldata.standardize_all()\n",
    "esldata.compute_agg(True)\n",
    "esldata.clean_covariance()\n",
    "\n",
    "ap = pd.read_csv(\"ap.csv\")\n",
    "apdata = agg_dataset()\n",
    "apdata.load(ap, [], [\"DBN\"], \"ap\")\n",
    "apdata.find_features()\n",
    "apdata.remove_redundant_columns()\n",
    "apdata.standardize_all()\n",
    "apdata.compute_agg(True)\n",
    "apdata.clean_covariance()\n",
    "\n",
    "survey = pd.read_csv(\"2013_NYC_School_Survey.csv\")\n",
    "surveydata = agg_dataset()\n",
    "surveydata.load(survey, [], [\"DBN\"], \"survey\")\n",
    "surveydata.find_features()\n",
    "surveydata.remove_redundant_columns()\n",
    "surveydata.standardize_all()\n",
    "surveydata.compute_agg(True)\n",
    "surveydata.clean_covariance()\n",
    "\n",
    "base = pd.read_csv(\"base.csv\")\n",
    "basedata = agg_dataset()\n",
    "basedata.load(base, [], [\"DBN\"], \"base\")\n",
    "basedata.find_features()\n",
    "basedata.remove_redundant_columns()\n",
    "basedata.standardize_all()\n",
    "basedata.compute_agg(True)\n",
    "basedata.clean_covariance()\n",
    "\n",
    "disc = pd.read_csv(\"disc.csv\")\n",
    "discdata = agg_dataset()\n",
    "discdata.load(disc, [], [\"DBN\"], \"disc\")\n",
    "discdata.find_features()\n",
    "discdata.remove_redundant_columns()\n",
    "discdata.standardize_all()\n",
    "discdata.compute_agg(True)\n",
    "discdata.clean_covariance()\n",
    "\n",
    "math = pd.read_csv(\"math.csv\")\n",
    "mathdata = agg_dataset()\n",
    "mathdata.load(math, [], [[\"DBN\",\"Grade\"]], \"math\")\n",
    "mathdata.find_features()\n",
    "mathdata.remove_redundant_columns()\n",
    "mathdata.standardize_all()\n",
    "mathdata.compute_agg(True)\n",
    "mathdata.clean_covariance()\n",
    "\n",
    "oss = pd.read_csv(\"oss.csv\")\n",
    "ossdata = agg_dataset()\n",
    "ossdata.load(oss, [], [\"DBN\"], \"oss\")\n",
    "ossdata.find_features()\n",
    "ossdata.remove_redundant_columns()\n",
    "ossdata.standardize_all()\n",
    "ossdata.compute_agg(True)\n",
    "ossdata.clean_covariance()\n",
    "\n",
    "pe = pd.read_csv(\"pe.csv\")\n",
    "pedata = agg_dataset()\n",
    "pedata.load(pe, [], [\"DBN\"], \"pe\")\n",
    "pedata.find_features()\n",
    "pedata.remove_redundant_columns()\n",
    "pedata.standardize_all()\n",
    "pedata.compute_agg(True)\n",
    "pedata.clean_covariance()\n",
    "\n",
    "s2tr = pd.read_csv(\"s2tr.csv\")\n",
    "s2trdata = agg_dataset()\n",
    "s2trdata.load(s2tr, [], [\"DBN\"], \"s2tr\")\n",
    "s2trdata.find_features()\n",
    "s2trdata.remove_redundant_columns()\n",
    "s2trdata.standardize_all()\n",
    "s2trdata.compute_agg(True)\n",
    "s2trdata.clean_covariance()\n",
    "\n",
    "sat = pd.read_csv(\"sat.csv\")\n",
    "satdata = agg_dataset()\n",
    "satdata.load(sat, [], [\"DBN\"], \"sat\")\n",
    "satdata.find_features()\n",
    "satdata.remove_redundant_columns()\n",
    "satdata.standardize_all()\n",
    "satdata.compute_agg(True)\n",
    "satdata.clean_covariance()\n",
    "\n",
    "pro = pd.read_csv(\"Schools_Progress_Report_2012-2013.csv\")\n",
    "prodata = agg_dataset()\n",
    "prodata.load(pro, [], [\"DBN\"], \"pro\")\n",
    "prodata.find_features()\n",
    "prodata.remove_redundant_columns()\n",
    "prodata.standardize_all()\n",
    "prodata.compute_agg(True)\n",
    "prodata.clean_covariance()\n",
    "\n",
    "spy = pd.read_csv(\"spy.csv\")\n",
    "spydata = agg_dataset()\n",
    "spydata.load(spy, [], [\"Year\"], \"spy\")\n",
    "spydata.find_features()\n",
    "spydata.remove_redundant_columns()\n",
    "spydata.standardize_all()\n",
    "spydata.compute_agg(True)\n",
    "spydata.clean_covariance()\n",
    "\n",
    "transfer = pd.read_csv(\"transfer.csv\")\n",
    "transferdata = agg_dataset()\n",
    "transferdata.load(transfer, [], [\"DBN\"], \"transfer\")\n",
    "transferdata.find_features()\n",
    "transferdata.remove_redundant_columns()\n",
    "transferdata.standardize_all()\n",
    "transferdata.compute_agg(True)\n",
    "transferdata.clean_covariance()\n",
    "\n",
    "yabc = pd.read_csv(\"yabc.csv\")\n",
    "yabcdata = agg_dataset()\n",
    "yabcdata.load(yabc, [], [\"DBN\"], \"yabc\")\n",
    "yabcdata.find_features()\n",
    "yabcdata.remove_redundant_columns()\n",
    "yabcdata.standardize_all()\n",
    "yabcdata.compute_agg(True)\n",
    "yabcdata.clean_covariance()\n",
    "\n",
    "dm1 = pd.read_csv(\"other/datamart.socrata.data-cityofnewyork-us.22rr-ujq3\")\n",
    "dm1data = agg_dataset()\n",
    "dm1data.load(dm1, [], [\"DBN\"], \"dm1\")\n",
    "dm1data.find_features()\n",
    "dm1data.remove_redundant_columns()\n",
    "dm1data.standardize_all()\n",
    "dm1data.compute_agg(True)\n",
    "dm1data.clean_covariance()\n",
    "\n",
    "dm2 = pd.read_csv(\"other/datamart.socrata.data-cityofnewyork-us.25aa-q86c\")\n",
    "dm2data = agg_dataset()\n",
    "dm2data.load(dm2, [], [\"DBN\"], \"dm2\")\n",
    "dm2data.find_features()\n",
    "dm2data.remove_redundant_columns()\n",
    "dm2data.standardize_all()\n",
    "dm2data.compute_agg(True)\n",
    "dm2data.clean_covariance()\n",
    "\n",
    "dm3 = pd.read_csv(\"other/datamart.socrata.data-cityofnewyork-us.29bv-qqsy\")\n",
    "dm3data = agg_dataset()\n",
    "dm3data.load(dm3, [], [\"DBN\"], \"dm3\")\n",
    "dm3data.find_features()\n",
    "dm3data.remove_redundant_columns()\n",
    "dm3data.standardize_all()\n",
    "dm3data.compute_agg(True)\n",
    "dm3data.clean_covariance()\n",
    "\n",
    "dm4 = pd.read_csv(\"other/datamart.socrata.data-cityofnewyork-us.29ry-u5bf\")\n",
    "dm4data = agg_dataset()\n",
    "dm4data.load(dm4, [], [\"DBN\"], \"dm4\")\n",
    "dm4data.find_features()\n",
    "dm4data.remove_redundant_columns()\n",
    "dm4data.standardize_all()\n",
    "dm4data.compute_agg(True)\n",
    "dm4data.clean_covariance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a59429f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d59260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7847887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers = []\n",
    "for i in range(10):\n",
    "    ran_df = pd.read_csv(\"random_dbn_data.csv\")\n",
    "    ran_df[\"att1\"] = np.random.randint(1, 100, 2000)\n",
    "    ran_df[\"att2\"] = np.random.randint(1, 100, 2000)\n",
    "    ran_df[\"att3\"] = np.random.randint(1, 100, 2000)\n",
    "    ran_df[\"att4\"] = np.random.randint(1, 100, 2000)\n",
    "    ran_df[\"att5\"] = np.random.randint(1, 100, 2000)\n",
    "    randomdata = agg_dataset()\n",
    "    randomdata.load(ran_df, [], [\"DBN\"], \"random\" + str(i))\n",
    "    randomdata.find_features()\n",
    "    randomdata.remove_redundant_columns()\n",
    "    randomdata.standardize_all()\n",
    "    randomdata.compute_agg(True)\n",
    "    randomdata.clean_covariance()\n",
    "    sellers.append((randomdata, \"random\" + str(i)))\n",
    "    \n",
    "sellersdict = dict()\n",
    "\n",
    "for sellerdata, dimension in sellers:\n",
    "    sellersdict[sellerdata.name] = sellerdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9fb0f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers = [(crimedata, \"DBN\"), (apdata, \"DBN\"), (surveydata, \"DBN\"), \n",
    "           (basedata, \"DBN\"), (discdata, \"DBN\"), \n",
    "           (ossdata, \"DBN\"), (pedata, \"DBN\"), \n",
    "           (s2trdata, \"DBN\"), (satdata, \"DBN\"), (prodata, \"DBN\"),\n",
    "           (transferdata, \"DBN\"), (yabcdata, \"DBN\"), (dm1data, \"DBN\"),\n",
    "           (dm2data, \"DBN\"), (dm3data, \"DBN\"), (dm4data, \"DBN\")]\n",
    "\n",
    "sellersdict = dict()\n",
    "\n",
    "for sellerdata, dimension in sellers:\n",
    "    sellersdict[sellerdata.name] = sellerdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6adfbf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sellerdata, dimension in sellers:\n",
    "    print(sellerdata.name)\n",
    "    dim_idx.absorb(sellerdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61d9e4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random0\n",
      "random1\n",
      "random2\n",
      "random3\n",
      "random4\n",
      "random5\n",
      "random6\n",
      "random7\n",
      "random8\n",
      "random9\n",
      "CPU times: user 1.23 s, sys: 35.3 ms, total: 1.26 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# care about left/right ojoin\n",
    "# notice that left table is not missing value imputated\n",
    "# this is O(n m^2)\n",
    "dim_idx = index(\"DBN\")\n",
    "for sellerdata, _ in sellers:\n",
    "    print(sellerdata.name)\n",
    "    dim_idx.absorb(sellerdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "89bd3a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 selected out of 50\n",
      "CPU times: user 26.8 ms, sys: 0 ns, total: 26.8 ms\n",
      "Wall time: 25.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dim_idx.compute_eigen_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc7af780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 432 ms, sys: 8.25 ms, total: 440 ms\n",
      "Wall time: 434 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:92: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dim_idx.compute_pc_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5be4d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 ms, sys: 2 Âµs, total: 1.3 ms\n",
      "Wall time: 1.31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dim_idx.compute_seller_contribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78b4f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read seller dataset and split into train/test\n",
    "gender = pd.read_csv(\"gender.csv\")\n",
    "\n",
    "# train test split\n",
    "msk = split_mask(len(gender)) < 0.8\n",
    "gender_train = gender[msk].copy()\n",
    "gender_test = gender[~msk].copy()\n",
    "\n",
    "gender_train_data = agg_dataset()\n",
    "gender_train_data.load(gender_train, [\"Number Tested\", \"Mean Scale Score\"], [\"DBN\", [\"DBN\",\"Grade\"], \"Year\", \"Category\"], \"gender\")\n",
    "gender_train_data.process_target(\"Mean Scale Score\")\n",
    "gender_train_data.to_numeric_and_impute_all()\n",
    "gender_train_data.remove_redundant_columns()\n",
    "gender_train_data.compute_agg()\n",
    "\n",
    "gender_test_data = agg_dataset()\n",
    "gender_test_data.load(gender_test, [\"Number Tested\", \"Mean Scale Score\"], [\"DBN\", [\"DBN\",\"Grade\"], \"Year\", \"Category\"], \"gender\")\n",
    "gender_test_data.process_target(\"Mean Scale Score\")\n",
    "gender_test_data.to_numeric_and_impute_all()\n",
    "gender_test_data.remove_redundant_columns()\n",
    "gender_test_data.compute_agg()\n",
    "\n",
    "y = \"Mean Scale Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7dfe0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pro:2012-2013 PERFORMANCE CATEGORY SCORE', 'dm2:MATH %Level 1', 'pro:2012-2013 ADDITIONAL CREDIT', 'f9'] 0.45914810498980463\n",
      "CPU times: user 206 ms, sys: 4.03 ms, total: 210 ms\n",
      "Wall time: 208 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:350: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cur_atts, final_r2 = select_features(gender_train_data, gender_test_data, dim_idx, \"DBN\", 10, y, pca=True)\n",
    "print(cur_atts, final_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1c004867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pro:2012-2013 PERFORMANCE CATEGORY SCORE',\n",
       " 'dm2:MATH %Level 1',\n",
       " 'pro:2012-2013 ADDITIONAL CREDIT',\n",
       " 'survey:Total Safety and Respect Score',\n",
       " 'gender:Mean Scale Score']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_train_data.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bb418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d7651911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49c9ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "random3 ['gender:Number Tested', 'random3:att5', 'random3:att2', 'random3:att1', 'random3:att3'] 0.01181847365320876\n",
      "9\n",
      "random7 ['gender:Number Tested', 'random7:att2', 'random3:att5', 'random7:att4', 'random3:att2', 'random3:att1', 'random3:att3', 'random7:att5', 'random7:att1'] 0.013785341845615307\n",
      "0\n",
      "random1 ['gender:Number Tested', 'random7:att2', 'random3:att5', 'random1:att1', 'random1:att4', 'random7:att4', 'random1:att5', 'random1:att3', 'random3:att1', 'random3:att2'] 0.016577316868286673\n",
      "8\n",
      "random0 ['gender:Number Tested', 'random7:att2', 'random3:att5', 'random1:att1', 'random1:att4', 'random0:att3', 'random1:att5', 'random7:att4', 'random0:att5', 'random0:att4'] 0.01760234331903987\n",
      "8\n",
      "random9 ['gender:Number Tested', 'random7:att2', 'random3:att5', 'random1:att1', 'random1:att4', 'random0:att3', 'random9:att1', 'random1:att5', 'random7:att4', 'random0:att5'] 0.01763355636018915\n",
      "CPU times: user 3.28 s, sys: 0 ns, total: 3.28 s\n",
      "Wall time: 3.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(5):\n",
    "    cur_atts, final_r2 = select_features(gender_train_data, gender_test_data, dim_idx, \"DBN\", 10, y, pca=True)\n",
    "    if cur_atts[-1].startswith(\"f\") and cur_atts[-1][1:].isnumeric():\n",
    "        # idx is the best pc\n",
    "        idx = int(cur_atts[-1][1:])\n",
    "        print(idx)\n",
    "        # find the seller dataset contributes to it most\n",
    "        for i in np.argsort(dim_idx.datasets_weights[idx])[::-1]:\n",
    "            sellername = dim_idx.datasets[i]\n",
    "            if sellername in gender_train_data.datasets:\n",
    "                continue\n",
    "\n",
    "            cur_atts2, final_r22 = select_features(gender_train_data, gender_test_data, sellersdict[sellername], \"DBN\",10,y)\n",
    "            print(sellername, cur_atts2, final_r22)\n",
    "            if len([x for x in cur_atts2 if x in sellersdict[sellername].X]) == 0:\n",
    "                # if not good, just add it to list, and exclude it\n",
    "                gender_train_data.datasets.add(sellername)\n",
    "                gender_test_data.datasets.add(sellername)\n",
    "            else:\n",
    "                gender_train_data.absorb(sellersdict[sellername], \"DBN\", cur_atts2 + [gender_train_data.name + \":\" + y])\n",
    "                gender_test_data.absorb(sellersdict[sellername], \"DBN\", cur_atts2 + [gender_train_data.name + \":\" + y])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b221c9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         15\n",
       "4          7\n",
       "5          9\n",
       "9         14\n",
       "10        12\n",
       "        ... \n",
       "47729    148\n",
       "47730    161\n",
       "47731    125\n",
       "47732    141\n",
       "47734    144\n",
       "Name: cov:s:gender:Number Tested, Length: 37981, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_train_data.data['cov:s:gender:Number Tested']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72255312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read seller dataset and split into train/test\n",
    "gender = pd.read_csv(\"gender.csv\")\n",
    "\n",
    "# train test split\n",
    "gender_train = gender[msk].copy()\n",
    "gender_test = gender[~msk].copy()\n",
    "\n",
    "gender_train_data = agg_dataset()\n",
    "gender_train_data.load(gender_train, [\"Number Tested\", \"Mean Scale Score\"], [\"DBN\", [\"DBN\",\"Grade\"], \"Year\", \"Category\"], \"gender\")\n",
    "gender_train_data.process_target(\"Mean Scale Score\")\n",
    "gender_train_data.to_numeric_and_impute_all()\n",
    "gender_train_data.remove_redundant_columns()\n",
    "gender_train_data.compute_agg()\n",
    "\n",
    "gender_test_data = agg_dataset()\n",
    "gender_test_data.load(gender_test, [\"Number Tested\", \"Mean Scale Score\"], [\"DBN\", [\"DBN\",\"Grade\"], \"Year\", \"Category\"], \"gender\")\n",
    "gender_test_data.process_target(\"Mean Scale Score\")\n",
    "gender_test_data.to_numeric_and_impute_all()\n",
    "gender_test_data.remove_redundant_columns()\n",
    "gender_test_data.compute_agg()\n",
    "\n",
    "y = \"Mean Scale Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ed5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4051bece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random0\n",
      "random1\n",
      "random2\n",
      "random3\n",
      "random4\n",
      "random5\n",
      "random6\n",
      "random7\n",
      "random8\n",
      "random9\n",
      "random4 ['gender:Number Tested', 'random4:att5', 'random4:att2', 'random4:att3', 'random4:att1', 'random4:att4'] 0.015612178033293955\n",
      "random0\n",
      "random1\n",
      "random2\n",
      "random3\n",
      "random5\n",
      "random6\n",
      "random7\n",
      "random8\n",
      "random9\n",
      "random1 ['gender:Number Tested', 'random4:att5', 'random4:att2', 'random1:att1', 'random1:att4', 'random1:att5', 'random4:att3', 'random1:att3', 'random1:att2', 'random4:att1'] 0.019088021138281785\n",
      "random0\n",
      "random2\n",
      "random3\n",
      "random5\n",
      "random6\n",
      "random7\n",
      "random8\n",
      "random9\n",
      "random6 ['gender:Number Tested', 'random4:att5', 'random4:att2', 'random6:att5', 'random1:att1', 'random1:att4', 'random1:att5', 'random6:att3', 'random6:att2', 'random6:att1'] 0.02144294569891725\n",
      "random0\n",
      "random2\n",
      "random3\n",
      "random5\n",
      "random7\n",
      "random8\n",
      "random9\n",
      "random8 ['gender:Number Tested', 'random4:att5', 'random4:att2', 'random8:att1', 'random1:att1', 'random6:att5', 'random1:att4', 'random1:att5', 'random6:att3', 'random8:att4'] 0.023172819356680696\n",
      "random0\n",
      "random2\n",
      "random3\n",
      "random5\n",
      "random7\n",
      "random9\n",
      "random2 ['gender:Number Tested', 'random4:att5', 'random4:att2', 'random2:att2', 'random8:att1', 'random1:att1', 'random6:att5', 'random1:att5', 'random1:att4', 'random6:att3'] 0.02457964464433371\n",
      "CPU times: user 6.45 s, sys: 44.3 ms, total: 6.49 s\n",
      "Wall time: 6.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(5):\n",
    "    best_seller = None\n",
    "    best_seller_attrs = []\n",
    "    best_dimension = None\n",
    "    best_r2 = 0\n",
    "    \n",
    "    for sellerdata, dimension in sellers:\n",
    "        # check if current seller has been bought\n",
    "        if sellerdata.name in gender_train_data.datasets:\n",
    "            continue\n",
    "        print(sellerdata.name)\n",
    "        \n",
    "         # find the attributes and r2 of augmenting\n",
    "        cur_atts, final_r2 = select_features(gender_train_data, gender_test_data, sellerdata, \"DBN\", 10, y)\n",
    "        \n",
    "        if final_r2 > best_r2:\n",
    "            best_seller = sellerdata\n",
    "            best_dimension = dimension\n",
    "            best_seller_attrs = cur_atts\n",
    "            best_r2 = final_r2\n",
    "    \n",
    "    print(best_seller.name, best_seller_attrs, best_r2)\n",
    "    \n",
    "    if len([x for x in best_seller_attrs if x in best_seller.X]) == 0:\n",
    "        gender_train_data.datasets.add(best_seller)\n",
    "        gender_test_data.datasets.add(best_seller)\n",
    "    else:\n",
    "        gender_train_data.absorb(best_seller, \"DBN\", best_seller_attrs + [gender_train_data.name + \":\" + y])\n",
    "        gender_test_data.absorb(best_seller, \"DBN\", best_seller_attrs + [gender_train_data.name + \":\" + y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c39b49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'random0'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fb39dbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19b31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m79"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
